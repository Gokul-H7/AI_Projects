{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "This project will perform sentiment analysis on statements to determine if they are positive or negative reviews of a movie. \n",
    "\n",
    "The dataset being used to train and test is a subset of the Stanford Sentiment Treebank containing 400 phrases which are split between equally between positive and negative.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section is for loading the training data from the google drive directory\n",
    "import os\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "dir_root = '/content/drive/MyDrive/Colab Notebooks/Assignment_1'\n",
    "train_file = os.path.join(dir_root, 'train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training data\n",
    "f = open('train.txt', 'r') # replace train.txt with train_file if using similar directory setup\n",
    "train_lines = f.readlines()\n",
    "f.close()\n",
    "\n",
    "# split the data into data and labels\n",
    "train_data, train_label = [], []\n",
    "for i in train_lines:\n",
    "  temp = i.split('|')\n",
    "  train_data.append(temp[0])\n",
    "  train_label.append(int(temp[1]))\n",
    "\n",
    "#preview some data here (for testing)\n",
    "preview = 10 # change preview # to see more or less data\n",
    "for i in range(preview):\n",
    "    print(f'Phrase \\\"{train_data[i]}\\\" has the sentiment {train_label[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Manually inspect word frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_frequency(data, label):\n",
    "    words = dict()\n",
    "    for i in range(len(data)):\n",
    "      temp = data[i].split(\" \")\n",
    "      for j in temp:\n",
    "        if j.lower() in words: # if the word is already in the dictionary\n",
    "          words[j.lower()]['total'] += 1\n",
    "          if label[i] == 1:\n",
    "            words[j.lower()]['pos'] += 1\n",
    "          else:\n",
    "            words[j.lower()]['neg'] += 1\n",
    "        else:\n",
    "          if label[i] == 1: # if the word is not in the dictionary\n",
    "            words[j.lower()] = {'total': 1, 'pos': 1, 'neg': 0}\n",
    "          else:\n",
    "            words[j.lower()] = {'total': 1, 'pos': 0, 'neg': 1}\n",
    "    return words\n",
    "\n",
    "words =  word_frequency(train_data, train_label)\n",
    "print('total' in words['best'] and 'pos' in words['best'] and 'neg' in words['best']) # True\n",
    "print(words['best']) # {'total': 12, 'pos': 12, 'neg': 0}\n",
    "\n",
    "print('Top 20 positive words (largest ratio in positive posts)')\n",
    "display(sorted(words.items(), key=lambda x: (x[1]['pos']/x[1]['total'], x[1]['total']), reverse=True)[:20])\n",
    "# [('best', {'total': 12, 'pos': 12, 'neg': 0}),\n",
    "# ('brilliant', {'total': 6, 'pos': 6, 'neg': 0}), ...\n",
    "print('Top 20 negative words (largest ratio in negative posts)')\n",
    "display(sorted(words.items(), key=lambda x: (x[1]['neg']/x[1]['total'], x[1]['total']), reverse=True)[:20])\n",
    "# [('i', {'total': 11, 'pos': 0, 'neg': 11}),\n",
    "#  ('bad', {'total': 10, 'pos': 0, 'neg': 10}), ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create the classifier\n",
    "\n",
    "The handcrafted classifier for the sentiment analysis model was created through trial and error using the evaluate function with the train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analysis_model(phrase):\n",
    "    # handcrafted classifier\n",
    "    pos = ['best', 'brilliant', 'films', 'work', 'first', 'love', 'recent', 'often', 'easily', 'performances', 'deserves', 'funny', 'well', 'triumph', 'moving', 'beautiful', 'season', 'dazzling']\n",
    "    neg = ['i', 'if', 'bad', 'worst', 'unlikable', 'utterly', 'pathetic', 'dull', 'pointless', 'ugly', 'barely', 'incompetent', 'waste', 'product', 'annoying', 'stale']\n",
    "\n",
    "    for i in pos:\n",
    "      if i in phrase.lower(): return 1\n",
    "    for i in neg:\n",
    "      if i in phrase.lower(): return -1\n",
    "\n",
    "    return 1 # default to positive\n",
    "\n",
    "def evaluate(func, data, label):\n",
    "    # evaluate the accuracy of the model passed in func\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i in range(len(data)):\n",
    "      if func(data[i]) == label[i]:\n",
    "        correct += 1\n",
    "        total += 1\n",
    "      else:\n",
    "        total += 1\n",
    "\n",
    "    accuracy = correct / total\n",
    "    return accuracy\n",
    "\n",
    "# use training data to evaluate the model\n",
    "train_acc = evaluate(sentiment_analysis_model, train_data, train_label)\n",
    "print(f\"Your method has the training accuracy of {train_acc*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section is for loading the test data from the google drive directory\n",
    "import sys\n",
    "sys.path.append(dir_root)\n",
    "test_dir = os.path.join(dir_root, 'test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# function that compares model output to test data\n",
    "def test(test_dir, func):\n",
    "\n",
    "    (test_data, test_label) = np.load(test_dir)\n",
    "\n",
    "    score = 0\n",
    "    for idx in range(len(test_data)):\n",
    "        if int(func(test_data[idx])) == int(test_label[idx]):\n",
    "            score += 1\n",
    "\n",
    "    return score / len(test_data)\n",
    "\n",
    "test_acc = test('test.npy', sentiment_analysis_model) # replace 'test.npy' with test_dir if using similar directory setup\n",
    "print(f\"Your method has the test accuracy of {test_acc*100}%\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
