{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "This project will perform sentiment analysis on statements to determine if they are positive or negative reviews of a movie. \n",
    "\n",
    "The dataset being used to train and test is a subset of the Stanford Sentiment Treebank containing 400 phrases which are split between equally between positive and negative.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section is for loading the training data from the google drive directory\n",
    "import os\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "dir_root = '/content/drive/MyDrive/Colab Notebooks/Assignment_1'\n",
    "train_file = os.path.join(dir_root, 'train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phrase \"Astonishingly skillful and moving\" has the sentiment 1\n",
      "Phrase \"are incredibly beautiful to look at\" has the sentiment 1\n",
      "Phrase \"as the most magical and most fun family fare of this or any recent holiday season\" has the sentiment 1\n",
      "Phrase \"It shows that some studios firmly believe that people have lost the ability to think and will forgive any shoddy product as long as there 's a little girl-on-girl action .\" has the sentiment -1\n",
      "Phrase \"Will assuredly rank as one of the cleverest , most deceptively amusing comedies of the year .\" has the sentiment 1\n",
      "Phrase \"disintegrates into a dreary , humorless soap opera\" has the sentiment -1\n",
      "Phrase \"The editing is chaotic , the photography grainy and badly focused , the writing unintentionally hilarious , the direction unfocused ,\" has the sentiment -1\n",
      "Phrase \"The film is often filled with a sense of pure wonderment and excitement not often seen in today 's cinema du sarcasm\" has the sentiment 1\n",
      "Phrase \"is as appalling as any ` comedy ' to ever spill from a projector 's lens\" has the sentiment -1\n",
      "Phrase \"... could easily be called the best Korean film of 2002 .\" has the sentiment 1\n"
     ]
    }
   ],
   "source": [
    "# load training data\n",
    "f = open('train.txt', 'r') # replace train.txt with train_file if using similar directory setup\n",
    "train_lines = f.readlines()\n",
    "f.close()\n",
    "\n",
    "# split the data into data and labels\n",
    "train_data, train_label = [], []\n",
    "for i in train_lines:\n",
    "  temp = i.split('|')\n",
    "  train_data.append(temp[0])\n",
    "  train_label.append(int(temp[1]))\n",
    "\n",
    "#preview some data here (for testing)\n",
    "preview = 10 # change preview # to see more or less data\n",
    "for i in range(preview):\n",
    "    print(f'Phrase \\\"{train_data[i]}\\\" has the sentiment {train_label[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Manually inspect word frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "{'total': 12, 'pos': 12, 'neg': 0}\n",
      "Top 20 positive words (largest ratio in positive posts)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('best', {'total': 12, 'pos': 12, 'neg': 0}),\n",
       " ('brilliant', {'total': 6, 'pos': 6, 'neg': 0}),\n",
       " ('films', {'total': 6, 'pos': 6, 'neg': 0}),\n",
       " ('work', {'total': 5, 'pos': 5, 'neg': 0}),\n",
       " ('first', {'total': 4, 'pos': 4, 'neg': 0}),\n",
       " ('love', {'total': 4, 'pos': 4, 'neg': 0}),\n",
       " ('their', {'total': 4, 'pos': 4, 'neg': 0}),\n",
       " ('recent', {'total': 3, 'pos': 3, 'neg': 0}),\n",
       " ('often', {'total': 3, 'pos': 3, 'neg': 0}),\n",
       " ('easily', {'total': 3, 'pos': 3, 'neg': 0}),\n",
       " ('performances', {'total': 3, 'pos': 3, 'neg': 0}),\n",
       " ('deserves', {'total': 3, 'pos': 3, 'neg': 0}),\n",
       " ('them', {'total': 3, 'pos': 3, 'neg': 0}),\n",
       " ('funny', {'total': 3, 'pos': 3, 'neg': 0}),\n",
       " ('well', {'total': 3, 'pos': 3, 'neg': 0}),\n",
       " ('triumph', {'total': 3, 'pos': 3, 'neg': 0}),\n",
       " ('adventure', {'total': 3, 'pos': 3, 'neg': 0}),\n",
       " ('moving', {'total': 2, 'pos': 2, 'neg': 0}),\n",
       " ('beautiful', {'total': 2, 'pos': 2, 'neg': 0}),\n",
       " ('season', {'total': 2, 'pos': 2, 'neg': 0})]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 negative words (largest ratio in negative posts)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('i', {'total': 11, 'pos': 0, 'neg': 11}),\n",
       " ('bad', {'total': 10, 'pos': 0, 'neg': 10}),\n",
       " ('worst', {'total': 6, 'pos': 0, 'neg': 6}),\n",
       " ('my', {'total': 4, 'pos': 0, 'neg': 4}),\n",
       " ('if', {'total': 4, 'pos': 0, 'neg': 4}),\n",
       " ('when', {'total': 4, 'pos': 0, 'neg': 4}),\n",
       " ('product', {'total': 3, 'pos': 0, 'neg': 3}),\n",
       " ('into', {'total': 3, 'pos': 0, 'neg': 3}),\n",
       " ('unlikable', {'total': 3, 'pos': 0, 'neg': 3}),\n",
       " ('utterly', {'total': 3, 'pos': 0, 'neg': 3}),\n",
       " ('pathetic', {'total': 3, 'pos': 0, 'neg': 3}),\n",
       " ('dull', {'total': 3, 'pos': 0, 'neg': 3}),\n",
       " (':', {'total': 3, 'pos': 0, 'neg': 3}),\n",
       " ('pointless', {'total': 3, 'pos': 0, 'neg': 3}),\n",
       " ('character', {'total': 3, 'pos': 0, 'neg': 3}),\n",
       " ('ugly', {'total': 3, 'pos': 0, 'neg': 3}),\n",
       " ('theater', {'total': 3, 'pos': 0, 'neg': 3}),\n",
       " ('he', {'total': 3, 'pos': 0, 'neg': 3}),\n",
       " ('barely', {'total': 3, 'pos': 0, 'neg': 3}),\n",
       " ('people', {'total': 2, 'pos': 0, 'neg': 2})]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def word_frequency(data, label):\n",
    "    words = dict()\n",
    "    for i in range(len(data)):\n",
    "      temp = data[i].split(\" \")\n",
    "      for j in temp:\n",
    "        if j.lower() in words: # if the word is already in the dictionary\n",
    "          words[j.lower()]['total'] += 1\n",
    "          if label[i] == 1:\n",
    "            words[j.lower()]['pos'] += 1\n",
    "          else:\n",
    "            words[j.lower()]['neg'] += 1\n",
    "        else:\n",
    "          if label[i] == 1: # if the word is not in the dictionary\n",
    "            words[j.lower()] = {'total': 1, 'pos': 1, 'neg': 0}\n",
    "          else:\n",
    "            words[j.lower()] = {'total': 1, 'pos': 0, 'neg': 1}\n",
    "    return words\n",
    "\n",
    "words =  word_frequency(train_data, train_label)\n",
    "print('total' in words['best'] and 'pos' in words['best'] and 'neg' in words['best']) # True\n",
    "print(words['best']) # {'total': 12, 'pos': 12, 'neg': 0}\n",
    "\n",
    "print('Top 20 positive words (largest ratio in positive posts)')\n",
    "display(sorted(words.items(), key=lambda x: (x[1]['pos']/x[1]['total'], x[1]['total']), reverse=True)[:20])\n",
    "# [('best', {'total': 12, 'pos': 12, 'neg': 0}),\n",
    "# ('brilliant', {'total': 6, 'pos': 6, 'neg': 0}), ...\n",
    "print('Top 20 negative words (largest ratio in negative posts)')\n",
    "display(sorted(words.items(), key=lambda x: (x[1]['neg']/x[1]['total'], x[1]['total']), reverse=True)[:20])\n",
    "# [('i', {'total': 11, 'pos': 0, 'neg': 11}),\n",
    "#  ('bad', {'total': 10, 'pos': 0, 'neg': 10}), ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create the classifier\n",
    "\n",
    "The handcrafted classifier for the sentiment analysis model was created through trial and error using the evaluate function with the train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your method has the training accuracy of 78.5%\n"
     ]
    }
   ],
   "source": [
    "def sentiment_analysis_model(phrase):\n",
    "    # handcrafted classifier\n",
    "    pos = ['best', 'brilliant', 'films', 'work', 'first', 'love', 'recent', 'often', 'easily', 'performances', 'deserves', 'funny', 'well', 'triumph', 'moving', 'beautiful', 'season', 'dazzling']\n",
    "    neg = ['i', 'if', 'bad', 'worst', 'unlikable', 'utterly', 'pathetic', 'dull', 'pointless', 'ugly', 'barely', 'incompetent', 'waste', 'product', 'annoying', 'stale', 'shoddy']\n",
    "\n",
    "    for i in pos:\n",
    "      if i in phrase.lower(): return 1\n",
    "    for i in neg:\n",
    "      if i in phrase.lower(): return -1\n",
    "\n",
    "    return 1 # default to positive\n",
    "\n",
    "def evaluate(func, data, label):\n",
    "    # evaluate the accuracy of the model passed in func\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i in range(len(data)):\n",
    "      if func(data[i]) == label[i]:\n",
    "        correct += 1\n",
    "        total += 1\n",
    "      else:\n",
    "        total += 1\n",
    "\n",
    "    accuracy = correct / total\n",
    "    return accuracy\n",
    "\n",
    "# use training data to evaluate the model\n",
    "train_acc = evaluate(sentiment_analysis_model, train_data, train_label)\n",
    "print(f\"Your method has the training accuracy of {train_acc*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section is for loading the test data from the google drive directory\n",
    "import sys\n",
    "sys.path.append(dir_root)\n",
    "test_dir = os.path.join(dir_root, 'test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your method has the test accuracy of 61.0%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# function that compares model output to test data\n",
    "def test(test_dir, func):\n",
    "\n",
    "    (test_data, test_label) = np.load(test_dir)\n",
    "\n",
    "    score = 0\n",
    "    for idx in range(len(test_data)):\n",
    "        if int(func(test_data[idx])) == int(test_label[idx]):\n",
    "            score += 1\n",
    "\n",
    "    return score / len(test_data)\n",
    "\n",
    "test_acc = test('test.npy', sentiment_analysis_model) # replace 'test.npy' with test_dir if using similar directory setup\n",
    "print(f\"Your method has the test accuracy of {test_acc*100}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
